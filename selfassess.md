## Machine Learning Category 

1. Completed project individually without a partner (10 pts)

2. Implemented music generation or audio processing model (7 pts) - demucs_processor.py

3. Implemented speech recognition system using pretrained or custom models (Whisper, Wav2Vec, etc.) (7 pts) - whisper_processor.py

4. Made API calls to state-of-the-art model (GPT-4, Claude, Gemini) with meaningful integration into your system (5 pts) - chatgpt_censor.py, particularly lines 64-98

5. Used or fine-tuned a transformer language model (7 pts) - chatgpt_censor.py

6. Applied in-context learning with few short examples or chain of thought prompting (5 pts) - app.py, particularly in lines 164-168 and 219-271.

7. Deployed model as functional web application with user interface (10 pts) - app.py

8. Built multi-stage ML pipeline connecting outputs of one model to inputs of another (e.g., vision model to a language model to a text-to-speech model) (7 pts) - app.py, particularly in lines 112 - 217

9. Measured and reported inference time, throughput, or computational efficiency (3 pts)
eval.py, also see README.md and drive folders for csv outputs.

10. Used at least three distinct and appropriate evaluation metrics for your task (3 pts)
eval.py, also see drive folders for csv outputs and README.md. 

11. Analyzed model behavior on edge cases or out-of-distribution examples (5 pts)
README.md

12. Conducted both qualitative and quantitative evaluation with thoughtful discussion (5 pts)
README.md, also see videos

13. Modular code design with reusable functions and classes rather than monolithic scripts (3 pts)






## Following Directions
1. Ontime submission by 5 pm on Friday, December 5th Tuesday, December 9th (note that late submissions will be accepted but only for the normal 72 hour late period, and will not qualify for this rubric item).

2. Self-assessment submitted that follows guidelines for at most 15 selections in Machine Learning with evidence (note that failing to submit a self-assessment may result in a loss of credit for some overlooked rubric items during grading).

3. SETUP.md exists with clear, step-by-step installation instruction

4. requirements.txt or environment.yml file is included and accurate

5. README.md has What it Does section that describes in one paragraph what your project does

6. README.md has Quick Start section that concisely explains how to run your project

7. README.md has Video Links section with direct links to your demo and technical walkthrough videos

8. README.md has Evaluation section that presents any quantitative results, accuracy metrics, or qualitative outcomes from testing

9. Demo video is of the correct length and appropriate for non-specialist audience with no code shown

10. Technical walkthrough is of the correct length and clearly explains code structure, ML techniques, and key contributions

11. Attended 1-2 project workshop days
12. Attended 3-4 project workshop days
13. Attended 5-6 project workshop days



## Project Cohesion
1. README clearly articulates a single, unified project goal or research question

2. Project demo video effectively communicates why the project matters to a non-technical audience in non-technical terms

3. Project addresses a real-world problem or explores a meaningful research question

4. Technical walkthrough demonstrates how components work together synergistically (not just isolated experiments)

5. Project shows clear progression from problem → approach → solution → evaluation

6. Design choices are explicitly justified in videos or documentation

7. Evaluation metrics directly measure the stated project objectives

8. None of the major components awarded rubric item credit in the machine learning category are superfluous to the larger goals of the project (no unrelated "point collecting")

9. Clean codebase with readable code and no extraneous, stale, or unused files
